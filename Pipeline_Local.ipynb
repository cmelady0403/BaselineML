{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8bfd5d6-c955-4c75-b325-3cf1122dc1ef",
   "metadata": {},
   "source": [
    "# Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1dd38-6145-43d9-8fb9-87a312e1e5b3",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806b1fe6-f6d6-4020-aefc-fa5d6b2219a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name     role         type demographic  \\\n",
      "0          fixed_acidity  Feature   Continuous        None   \n",
      "1       volatile_acidity  Feature   Continuous        None   \n",
      "2            citric_acid  Feature   Continuous        None   \n",
      "3         residual_sugar  Feature   Continuous        None   \n",
      "4              chlorides  Feature   Continuous        None   \n",
      "5    free_sulfur_dioxide  Feature   Continuous        None   \n",
      "6   total_sulfur_dioxide  Feature   Continuous        None   \n",
      "7                density  Feature   Continuous        None   \n",
      "8                     pH  Feature   Continuous        None   \n",
      "9              sulphates  Feature   Continuous        None   \n",
      "10               alcohol  Feature   Continuous        None   \n",
      "11               quality   Target      Integer        None   \n",
      "12                 color    Other  Categorical        None   \n",
      "\n",
      "               description units missing_values  \n",
      "0                     None  None             no  \n",
      "1                     None  None             no  \n",
      "2                     None  None             no  \n",
      "3                     None  None             no  \n",
      "4                     None  None             no  \n",
      "5                     None  None             no  \n",
      "6                     None  None             no  \n",
      "7                     None  None             no  \n",
      "8                     None  None             no  \n",
      "9                     None  None             no  \n",
      "10                    None  None             no  \n",
      "11  score between 0 and 10  None             no  \n",
      "12            red or white  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine_quality.data.features \n",
    "y = wine_quality.data.targets \n",
    "  \n",
    "# variable information \n",
    "print(wine_quality.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e023a32-67b5-4b10-bf52-84cd70831477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined CSV file has been saved as 'wine_quality_combined.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) \n",
    "\n",
    "# Data (as pandas dataframes) \n",
    "X = wine_quality.data.features \n",
    "y = wine_quality.data.targets \n",
    "\n",
    "# Combine X and y into a single dataframe\n",
    "combined_df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "combined_df.to_csv('wine_quality_combined.csv', index=False)\n",
    "\n",
    "print(\"The combined CSV file has been saved as 'wine_quality_combined.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76464e30-8f82-4200-b982-ff23f6563391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('wine_quality_combined.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8da5bc-a31a-4bca-9fa3-034999aae7cd",
   "metadata": {},
   "source": [
    "## Ratio Customization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5d5b3e-b2f0-42cf-8922-8ec4c4678c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_trim_dataset(file_path, ratio=5):\n",
    "    \"\"\"\n",
    "    Load a dataset from a CSV file and trim it to have a specified observation to feature ratio.\n",
    "    Also, display the number of classes for the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: str, path to the CSV file\n",
    "    - ratio: int, the desired observation to feature ratio (default is 5)\n",
    "    \n",
    "    Returns:\n",
    "    - trimmed_df: pd.DataFrame, the trimmed dataset\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check the number of features and observations\n",
    "    n_features = df.shape[1] - 1  # Exclude the target column\n",
    "    n_observations = df.shape[0]\n",
    "    \n",
    "    # Calculate the required number of observations for the specified ratio\n",
    "    required_observations = n_features * ratio\n",
    "    \n",
    "    # Check if the dataset meets the observation to feature ratio\n",
    "    if n_observations < required_observations:\n",
    "        raise ValueError(f\"The dataset does not meet the {ratio}:1 observation to feature ratio. \"\n",
    "                         f\"Required observations: {required_observations}, but got {n_observations}.\")\n",
    "    \n",
    "    # Randomly select rows to meet the observation to feature ratio\n",
    "    trimmed_df = df.sample(n=required_observations, random_state=42)\n",
    "    \n",
    "    # Display the number of classes in the target column\n",
    "    target_column = df.columns[-1]\n",
    "    n_classes = df[target_column].nunique()\n",
    "    \n",
    "    print(f\"The dataset has {n_classes} classes.\")\n",
    "    \n",
    "    return trimmed_df\n",
    "\n",
    "# Example usage:\n",
    "# trimmed_df = load_and_trim_dataset('path_to_your_dataset.csv', ratio=5)\n",
    "# print(trimmed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "344164a4-d8fa-43a4-b92a-ceba8de013cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 7 classes.\n"
     ]
    }
   ],
   "source": [
    "trimmed_df = load_and_trim_dataset('wine_quality_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb8e408-52e7-48e3-83b2-66b9a746a4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.74</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.045</td>\n",
       "      <td>24.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.99420</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>32.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.020</td>\n",
       "      <td>38.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.99212</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4690</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.040</td>\n",
       "      <td>61.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.99592</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.20</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.054</td>\n",
       "      <td>63.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.99888</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.064</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.99323</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.61</td>\n",
       "      <td>12.10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.31</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.051</td>\n",
       "      <td>33.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.27</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.044</td>\n",
       "      <td>45.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.99454</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>9.90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.078</td>\n",
       "      <td>26.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.034</td>\n",
       "      <td>62.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99121</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.42</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.066</td>\n",
       "      <td>53.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.056</td>\n",
       "      <td>24.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99440</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.028</td>\n",
       "      <td>45.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.99168</td>\n",
       "      <td>3.21</td>\n",
       "      <td>1.08</td>\n",
       "      <td>12.15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.072</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.99670</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.054</td>\n",
       "      <td>19.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.99270</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>12.20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.27</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.040</td>\n",
       "      <td>44.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.69</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.080</td>\n",
       "      <td>33.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.34</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.059</td>\n",
       "      <td>42.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.99882</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>5.1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.022</td>\n",
       "      <td>44.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.99221</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.39</td>\n",
       "      <td>11.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.50</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.048</td>\n",
       "      <td>36.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.99904</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.54</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.046</td>\n",
       "      <td>58.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.99454</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.70</td>\n",
       "      <td>10.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>5.1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.034</td>\n",
       "      <td>36.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.99188</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>11.50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.028</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.99360</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>11.40</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6294</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>29.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99188</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12.90</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.36</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>35.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.99860</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8.90</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.42</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.045</td>\n",
       "      <td>62.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.99544</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.29</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.040</td>\n",
       "      <td>21.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.35</td>\n",
       "      <td>9.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.41</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.050</td>\n",
       "      <td>55.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.081</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99840</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.065</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99417</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.74</td>\n",
       "      <td>12.70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>17.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.99584</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.031</td>\n",
       "      <td>24.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.98960</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.35</td>\n",
       "      <td>12.20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.089</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.037</td>\n",
       "      <td>18.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99230</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.42</td>\n",
       "      <td>11.40</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.093</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.040</td>\n",
       "      <td>41.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.98968</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>13.10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.99586</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.091</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.055</td>\n",
       "      <td>42.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99318</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.44</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.045</td>\n",
       "      <td>68.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.99860</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.36</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.047</td>\n",
       "      <td>29.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99278</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.031</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.99194</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.105</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.031</td>\n",
       "      <td>48.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99170</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>11.50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.053</td>\n",
       "      <td>46.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>8.90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.055</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.99520</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.79</td>\n",
       "      <td>13.30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.059</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.032</td>\n",
       "      <td>32.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99458</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.50</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>8.7</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.084</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.99920</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.99740</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>10.90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.048</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99110</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.46</td>\n",
       "      <td>12.00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.093</td>\n",
       "      <td>11.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99888</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>11.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99106</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.42</td>\n",
       "      <td>11.10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "3103            7.0             0.170         0.74            12.8      0.045   \n",
       "1419            7.7             0.640         0.21             2.2      0.077   \n",
       "4761            6.8             0.390         0.34             7.4      0.020   \n",
       "4690            6.3             0.280         0.47            11.2      0.040   \n",
       "4032            7.4             0.350         0.20            13.9      0.054   \n",
       "1297            7.2             0.530         0.14             2.1      0.064   \n",
       "1773            7.5             0.270         0.31            17.7      0.051   \n",
       "5584            6.8             0.110         0.27             8.6      0.044   \n",
       "561             9.0             0.440         0.49             2.4      0.078   \n",
       "5946            7.1             0.230         0.30             2.6      0.034   \n",
       "1891            7.4             0.280         0.42            19.8      0.066   \n",
       "2264            7.8             0.280         0.22             1.4      0.056   \n",
       "6485            6.2             0.210         0.28             5.7      0.028   \n",
       "217             8.1             0.725         0.22             2.2      0.072   \n",
       "230             5.2             0.480         0.04             1.6      0.054   \n",
       "2168            6.5             0.280         0.27             5.2      0.040   \n",
       "1400            7.9             0.690         0.21             2.1      0.080   \n",
       "4355            8.6             0.330         0.34            11.8      0.059   \n",
       "4697            5.1             0.330         0.27             6.7      0.022   \n",
       "4295            6.5             0.220         0.50            16.4      0.048   \n",
       "4660            6.2             0.250         0.54             7.0      0.046   \n",
       "5417            5.1             0.350         0.26             6.8      0.034   \n",
       "3270            7.0             0.350         0.30             6.5      0.028   \n",
       "6294            6.7             0.350         0.32             9.0      0.032   \n",
       "2996            7.3             0.250         0.36            13.1      0.050   \n",
       "4147            6.3             0.260         0.42             7.1      0.045   \n",
       "2876            7.6             0.310         0.29            10.5      0.040   \n",
       "2955            7.3             0.220         0.41            15.4      0.050   \n",
       "496             7.8             0.520         0.25             1.9      0.081   \n",
       "828             7.8             0.570         0.09             2.3      0.065   \n",
       "1397            7.3             0.590         0.26             2.0      0.080   \n",
       "2127            5.2             0.360         0.02             1.6      0.031   \n",
       "1263            8.2             0.780         0.00             2.2      0.089   \n",
       "1963            6.8             0.160         0.40             2.3      0.037   \n",
       "706             7.0             0.780         0.08             2.0      0.093   \n",
       "5464            6.0             0.310         0.38             4.8      0.040   \n",
       "1375            7.2             0.560         0.26             2.0      0.083   \n",
       "585             7.6             0.510         0.24             2.4      0.091   \n",
       "4787            7.0             0.170         0.36             6.4      0.055   \n",
       "3326            7.6             0.445         0.44            14.5      0.045   \n",
       "1608            8.1             0.220         0.43             1.5      0.044   \n",
       "96              6.8             0.775         0.00             3.0      0.102   \n",
       "4453            6.4             0.210         0.28             5.9      0.047   \n",
       "3946            7.5             0.230         0.29             2.6      0.031   \n",
       "31              6.9             0.685         0.00             2.5      0.105   \n",
       "2807            6.3             0.210         0.40             1.7      0.031   \n",
       "2104            7.8             0.180         0.31            12.2      0.053   \n",
       "491             9.2             0.410         0.50             2.5      0.055   \n",
       "401             7.7             0.260         0.30             1.7      0.059   \n",
       "5009            8.9             0.300         0.35             4.6      0.032   \n",
       "712             8.7             0.690         0.00             3.2      0.084   \n",
       "1406            8.2             0.240         0.34             5.1      0.062   \n",
       "2957            6.8             0.350         0.32             2.4      0.048   \n",
       "764             9.1             0.680         0.11             2.8      0.093   \n",
       "4161            6.9             0.320         0.26             2.3      0.030   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "3103                 24.0                 126.0  0.99420  3.26       0.38   \n",
       "1419                 32.0                 133.0  0.99560  3.27       0.45   \n",
       "4761                 38.0                 133.0  0.99212  3.18       0.44   \n",
       "4690                 61.0                 183.0  0.99592  3.12       0.51   \n",
       "4032                 63.0                 229.0  0.99888  3.11       0.50   \n",
       "1297                 15.0                  29.0  0.99323  3.35       0.61   \n",
       "1773                 33.0                 173.0  0.99900  3.09       0.64   \n",
       "5584                 45.0                 104.0  0.99454  3.20       0.37   \n",
       "561                  26.0                 121.0  0.99780  3.23       0.58   \n",
       "5946                 62.0                 148.0  0.99121  3.03       0.56   \n",
       "1891                 53.0                 195.0  1.00000  2.96       0.44   \n",
       "2264                 24.0                 130.0  0.99440  3.28       0.48   \n",
       "6485                 45.0                 121.0  0.99168  3.21       1.08   \n",
       "217                  11.0                  41.0  0.99670  3.36       0.55   \n",
       "230                  19.0                 106.0  0.99270  3.54       0.62   \n",
       "2168                 44.0                 179.0  0.99480  3.19       0.69   \n",
       "1400                 33.0                 141.0  0.99620  3.25       0.51   \n",
       "4355                 42.0                 240.0  0.99882  3.17       0.52   \n",
       "4697                 44.0                 129.0  0.99221  3.36       0.39   \n",
       "4295                 36.0                 182.0  0.99904  3.02       0.49   \n",
       "4660                 58.0                 176.0  0.99454  3.19       0.70   \n",
       "5417                 36.0                 120.0  0.99188  3.38       0.40   \n",
       "3270                 27.0                  87.0  0.99360  3.40       0.42   \n",
       "6294                 29.0                 113.0  0.99188  3.13       0.65   \n",
       "2996                 35.0                 200.0  0.99860  3.04       0.46   \n",
       "4147                 62.0                 209.0  0.99544  3.20       0.53   \n",
       "2876                 21.0                 145.0  0.99660  3.04       0.35   \n",
       "2955                 55.0                 191.0  1.00000  3.32       0.59   \n",
       "496                  14.0                  38.0  0.99840  3.43       0.65   \n",
       "828                  34.0                  45.0  0.99417  3.46       0.74   \n",
       "1397                 17.0                 104.0  0.99584  3.28       0.52   \n",
       "2127                 24.0                 104.0  0.98960  3.44       0.35   \n",
       "1263                 13.0                  26.0  0.99780  3.37       0.46   \n",
       "1963                 18.0                 102.0  0.99230  3.49       0.42   \n",
       "706                  10.0                  19.0  0.99560  3.40       0.47   \n",
       "5464                 41.0                 101.0  0.98968  3.24       0.56   \n",
       "1375                 13.0                 100.0  0.99586  3.26       0.52   \n",
       "585                   8.0                  38.0  0.99800  3.47       0.66   \n",
       "4787                 42.0                 123.0  0.99318  3.11       0.50   \n",
       "3326                 68.0                 212.0  0.99860  3.48       0.36   \n",
       "1608                 28.0                 129.0  0.99380  3.22       0.45   \n",
       "96                    8.0                  23.0  0.99650  3.45       0.56   \n",
       "4453                 29.0                 101.0  0.99278  3.15       0.40   \n",
       "3946                 24.0                  98.0  0.99194  3.00       0.54   \n",
       "31                   22.0                  37.0  0.99660  3.46       0.57   \n",
       "2807                 48.0                 134.0  0.99170  3.42       0.49   \n",
       "2104                 46.0                 140.0  0.99800  3.06       0.53   \n",
       "491                  12.0                  25.0  0.99520  3.34       0.79   \n",
       "401                  20.0                  38.0  0.99490  3.29       0.47   \n",
       "5009                 32.0                 148.0  0.99458  3.15       0.45   \n",
       "712                  13.0                  33.0  0.99920  3.36       0.45   \n",
       "1406                  8.0                  22.0  0.99740  3.22       0.94   \n",
       "2957                 35.0                 103.0  0.99110  3.28       0.46   \n",
       "764                  11.0                  44.0  0.99888  3.31       0.55   \n",
       "4161                 11.0                 103.0  0.99106  3.06       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "3103    12.20        8  \n",
       "1419     9.90        5  \n",
       "4761    12.00        7  \n",
       "4690     9.50        6  \n",
       "4032     8.90        6  \n",
       "1297    12.10        6  \n",
       "1773    10.20        5  \n",
       "5584     9.90        6  \n",
       "561      9.20        5  \n",
       "5946    11.30        7  \n",
       "1891     9.10        5  \n",
       "2264     9.50        5  \n",
       "6485    12.15        7  \n",
       "217      9.10        5  \n",
       "230     12.20        7  \n",
       "2168     9.40        6  \n",
       "1400     9.90        5  \n",
       "4355    10.00        6  \n",
       "4697    11.00        7  \n",
       "4295     8.80        6  \n",
       "4660    10.40        5  \n",
       "5417    11.50        6  \n",
       "3270    11.40        7  \n",
       "6294    12.90        7  \n",
       "2996     8.90        7  \n",
       "4147     9.50        6  \n",
       "2876     9.40        5  \n",
       "2955     8.90        6  \n",
       "496      9.00        6  \n",
       "828     12.70        8  \n",
       "1397     9.90        5  \n",
       "2127    12.20        6  \n",
       "1263     9.60        4  \n",
       "1963    11.40        7  \n",
       "706     10.00        5  \n",
       "5464    13.10        6  \n",
       "1375     9.90        5  \n",
       "585      9.60        6  \n",
       "4787    11.00        8  \n",
       "3326    10.00        6  \n",
       "1608    11.00        6  \n",
       "96      10.70        5  \n",
       "4453    11.00        6  \n",
       "3946    10.90        6  \n",
       "31      10.60        6  \n",
       "2807    11.50        6  \n",
       "2104     8.90        6  \n",
       "491     13.30        7  \n",
       "401     10.80        6  \n",
       "5009    11.50        7  \n",
       "712      9.40        5  \n",
       "1406    10.90        6  \n",
       "2957    12.00        8  \n",
       "764      9.50        6  \n",
       "4161    11.10        6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee001bd-1b8c-4e68-bbf6-4fc28b0dc0ca",
   "metadata": {},
   "source": [
    "## Baseline Model Training and Original Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f64b69d-af7f-4b75-950c-6b1adfeb23ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Random Forest model: 0.27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # Import for Decision Tree\n",
    "from sklearn.svm import SVC  # Import for SVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming trimmed_df is your DataFrame with enough observations\n",
    "X = trimmed_df.drop(columns=['quality'])  # Features\n",
    "y = trimmed_df['quality']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (Random Forest)\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Accuracy of the Random Forest model: {rf_accuracy:.2f}\")\n",
    "\n",
    "# Train a Decision Tree model (Added)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (Decision Tree)\n",
    "dt_y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the Decision Tree model\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(f\"Accuracy of the Decision Tree model: {dt_accuracy:.2f}\")\n",
    "\n",
    "# Train an SVM model (Reintroduced)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (SVM)\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "print(f\"Accuracy of the SVM model: {svm_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee8d6983-0f6f-4ef3-9cb3-9b54a8b545e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Random Forest model with tuned parameters: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # Import for Decision Tree\n",
    "from sklearn.svm import SVC  # Import for SVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train a Random Forest model with tuned parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=3,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the Random Forest model to your training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (Random Forest)\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the Random Forest model with tuned parameters\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Accuracy of the Random Forest model with tuned parameters: {rf_accuracy:.2f}\")\n",
    "\n",
    "# Train a Decision Tree model (Added)\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=10,  # You can tune this if needed\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the Decision Tree model to your training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (Decision Tree)\n",
    "dt_y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the Decision Tree model\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(f\"Accuracy of the Decision Tree model: {dt_accuracy:.2f}\")\n",
    "\n",
    "# Train an SVM model with default parameters (Reintroduced)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (SVM)\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "print(f\"Accuracy of the SVM model: {svm_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ab2ac9d-3367-4d18-a732-d86c366a952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dagin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.50\n",
      "Accuracy of the Random Forest model with tuned parameters: 0.27\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.33      0.33      0.33         3\n",
      "           6       0.25      0.25      0.25         4\n",
      "           7       0.25      0.50      0.33         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27        11\n",
      "   macro avg       0.17      0.22      0.18        11\n",
      "weighted avg       0.23      0.27      0.24        11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dagin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dagin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dagin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # Import for Decision Tree\n",
    "from sklearn.svm import SVC  # Import for SVM\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Separate features and target variable\n",
    "X = trimmed_df.drop(columns=['quality'])\n",
    "y = trimmed_df['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning (Random Forest)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation for Random Forest\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best score from grid search (Random Forest)\n",
    "print(f\"Best parameters (Random Forest): {grid_search_rf.best_params_}\")\n",
    "print(f\"Best cross-validation score (Random Forest): {grid_search_rf.best_score_:.2f}\")\n",
    "\n",
    "# Train a Random Forest model with tuned parameters\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (Random Forest)\n",
    "rf_y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Accuracy of the Random Forest model with tuned parameters: {rf_accuracy:.2f}\")\n",
    "\n",
    "# Decision Tree: Define parameter grid for hyperparameter tuning\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation for Decision Tree\n",
    "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best score from grid search (Decision Tree)\n",
    "print(f\"Best parameters (Decision Tree): {grid_search_dt.best_params_}\")\n",
    "print(f\"Best cross-validation score (Decision Tree): {grid_search_dt.best_score_:.2f}\")\n",
    "\n",
    "# Train a Decision Tree model with tuned parameters\n",
    "best_dt_model = grid_search_dt.best_estimator_\n",
    "best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (Decision Tree)\n",
    "dt_y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the Decision Tree model\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(f\"Accuracy of the Decision Tree model: {dt_accuracy:.2f}\")\n",
    "\n",
    "# SVM: Define parameter grid for hyperparameter tuning (Reintroduced)\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation for SVM\n",
    "grid_search_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best score from grid search (SVM)\n",
    "print(f\"Best parameters (SVM): {grid_search_svm.best_params_}\")\n",
    "print(f\"Best cross-validation score (SVM): {grid_search_svm.best_score_:.2f}\")\n",
    "\n",
    "# Train an SVM model with tuned parameters\n",
    "best_svm_model = grid_search_svm.best_estimator_\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (SVM)\n",
    "svm_y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "print(f\"Accuracy of the SVM model: {svm_accuracy:.2f}\")\n",
    "\n",
    "# Print classification reports and confusion matrices for each model\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\nClassification Report (Random Forest):\")\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "cm_rf = confusion_matrix(y_test, rf_y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=best_rf_model.classes_, yticklabels=best_rf_model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Random Forest)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "print(\"\\nClassification Report (Decision Tree):\")\n",
    "print(classification_report(y_test, dt_y_pred))\n",
    "cm_dt = confusion_matrix(y_test, dt_y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', xticklabels=best_dt_model.classes_, yticklabels=best_dt_model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Decision Tree)')\n",
    "plt.show()\n",
    "\n",
    "# SVM\n",
    "print(\"\\nClassification Report (SVM):\")\n",
    "print(classification_report(y_test, svm_y_pred))\n",
    "cm_svm = confusion_matrix(y_test, svm_y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=best_svm_model.classes_, yticklabels=best_svm_model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (SVM)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
